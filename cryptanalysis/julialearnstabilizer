# Every block cipher round function induces an action of the free group generated by all possible round keys on the set of all possible messages.
# In this post, a neural network learns to tell the difference between a string generated at random and a string that is in a pre-determined coset of a stabilizer group
# of this action. At the moment, this code is simply a proof-of-concept but it is not optimized in any way. The neural network is a feedforward neural network with one
# or several hidden layers. This neural network can be used to investigate the cryptographic security of block cipher round functions in a way so that isomorphic
# block cipher round functions are endowed with the exact same level of cryptographic security. We can modify the code so that it includes a Boolean combinatorial
# circuit layer before the dense neural network, and such modifications should improve the ability of the neural network to determine stabilizer groups.

using Flux, CUDA, Random

function shift(x) 
local n,y
n=length(x)
y=Vector{Int64}(undef, n)

for i in 2:n
y[i]=x[i-1]
end
y[1]=x[n]
return y
end

function invshift(x)
local n,y;
n=length(x)
y=Vector{Int64}(undef,n)
for i in 1:n-1
y[i]=x[i+1]
end
y[n]=x[1]
return y
end

function gates(x)

x[1]=(x[1]+x[14]*x[22])%2
x[6]=(x[6]+x[7])%2
x[9]=(x[9]+x[14])%2
end

#here we assume gates is self invertible


function preshiftgates(bit,x)
y=shift(x)
y[1]=(y[1]+bit)%2
gates(y)
return y
end

function preinvshiftgates(bit,x)
y=copy(x)
gates(y)
y[1]=(y[1]+bit)%2
return invshift(y)
end

function shiftgates(b,x)
return preshiftgates(b,x)
#return preshiftgates(0,preshiftgates(b,x))
end

function invshiftgates(b,x)
return preinvshiftgates(b,x)
#return preinvshiftgates(0,preinvshiftgates(b,x))
end


function iteratedshiftgates(key,x)
y=copy(x)
for b in key
y=shiftgates(b,y)
end
return y
end

function inviteratedshiftgates(key,x)
y=copy(x)
yek=reverse(key)
for b in yek
y=invshiftgates(b,y)
end
return y
end



n=Int(24)

mm=Int(46)

lefthalfmm=Int((mm-mm%2)/2)
righthalfmm=mm-lefthalfmm

leftdict=Dict()
invleftdict=Dict()
rightdict=Dict()
invrightdict=Dict()

lim=100000

learn=[]
aa=bitrand(n)
qq=rand(1:n)
aa[qq]=1-aa[qq]

function mars()

if length(leftdict)>lim
pop!(leftdict)
end
if length(rightdict)>lim
pop!(rightdict)
end
if length(invleftdict)>lim
pop!(invleftdict)
end
if length(invrightdict)>lim
pop!(invrightdict)
end

axe=length(learn)
while length(learn)==axe
leftbits=bitrand(lefthalfmm)

if !haskey(leftdict,leftbits)
aaa=iteratedshiftgates(leftbits,aa)
leftdict[leftbits]=aaa
invleftdict[aaa]=leftbits
else
aaa=leftdict[leftbits]
end

if haskey(invrightdict,aaa)
push!(learn,vcat(leftbits,invrightdict[aaa]))
delete!(rightdict,invrightdict[aaa])
delete!(invrightdict,aaa)
delete!(leftdict,leftbits)
delete!(invleftdict,aaa)
end

rightbits=bitrand(righthalfmm)

if !haskey(rightdict,rightbits)
aaa=inviteratedshiftgates(rightbits,aa)
rightdict[rightbits]=aaa
invrightdict[aaa]=rightbits
else
aaa=rightdict[rightbits]
end

if haskey(invleftdict,aaa)
push!(learn,vcat(invleftdict[aaa],rightbits))
delete!(leftdict,invleftdict[aaa])
delete!(invleftdict,aaa)
delete!(rightdict,rightbits)
delete!(invrightdict,aaa)
end
end
end

mars()


ham=16

haha=64

discriminator=Chain(Dense(mm,haha,tanh),Dense(haha,haha,tanh),Dense(haha,1,sigmoid))

rng = MersenneTwister(1234);

qq=100

lambda=0

lossdisc(x)=(discriminator(x[1])[1]-x[2])^2

lossdisc(x,y)=(discriminator(x)[1]-y)^2

rate=0.01;
psdisc=Flux.params(discriminator)
opt = Descent(rate)
can=true;

old=0.0;
new=0.0;
cc=0.0
dd=0.0
for jj in 1:1000000
opt = Descent(rate);
if dd-cc>0.05
mars()
cc=cc*0.99
if (discriminator(float.(learn[length(learn)]))[1]>discriminator(float.(bitrand(mm)))[1])
cc=cc+0.01
end
end

dd=dd*0.99
if (discriminator(float.(rand(learn)))[1]>discriminator(float.(bitrand(mm)))[1])
dd=dd+0.01
end

display(cc)
display(dd)
display(rate)
display(length(learn))
display(".")

datadisc=[]
for i in 1:qq
push!(datadisc,(float.(rand(learn)),1.));
push!(datadisc,(float.(bitrand(mm)),0.));
end

tar=(rand(1:10)==1);

if tar||can
old=sum(lossdisc.(datadisc));
end;

Flux.train!(lossdisc,psdisc,datadisc,opt)

if tar||can
new=sum(lossdisc.(datadisc));
if old<new
rate=rate*0.5;
can=false;
end;
rate=rate*1.01;
end;
end;


